{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weisja15\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bini(A, B, steps, e=1e-8):\n",
    "    \n",
    "    #Check Dimensions\n",
    "    (m, n) = A.get_shape().as_list()\n",
    "    #rn assuming that m is bigger than n, nn and p\n",
    "    (nn, p) = B.get_shape().as_list()\n",
    "    if n != nn: raise ValueError(\"incompatible dimensions\")\n",
    "    \n",
    "    #pre-allocate output matrix\n",
    "    C = tf.zeros([m,p])\n",
    "    \n",
    "    \"\"\"\n",
    "    This is the notation I use from Bini's 1980 paper\n",
    "\n",
    "    |A1, A4|  |B1, B2|  =  |C1, C2|\n",
    "    |A2, A5|  |B3, B4|     |C3, C4|\n",
    "    |A3, A6|               |C5, C6|\n",
    "    \"\"\"\n",
    "    \n",
    "    #Base case\n",
    "    if steps == 0 or m == 1 or n == 1 or p == 1:\n",
    "        C = tf.matmul(A,B)\n",
    "        return C\n",
    "    \n",
    "    #Static peeling\n",
    "    if (3**steps > m) or (2**steps > n) or (2**steps > p):\n",
    "        raise ValueError(\"Too many steps/ too small matricies for static peeling\")\n",
    "    \n",
    "    if (m % 3**steps) != 0:\n",
    "        print(\"Statics Peel 1\")\n",
    "        extra_rows = m % 3**steps\n",
    "        \n",
    "        #C[:m-extra_rows, :] = \n",
    "        Cmat = bini(A[:m-extra_rows, :], B, steps, e)\n",
    "        #C[m-extra_rows:, :] =\n",
    "        \n",
    "        # need to expand dims if slice of A is a vector, and expand dims if it is\n",
    "        A_slice = A[m-extra_rows:, :]\n",
    "        (slice_len, _) = A_slice.get_shape().as_list()\n",
    "        if slice_len == 1:\n",
    "            #vector case\n",
    "            Crow = tf.matmul(tf.expand_dims(A_slice, 0), B)\n",
    "        \n",
    "        else:\n",
    "            # don't need to expand dims\n",
    "            Crow = tf.matmul(A_slice, B)\n",
    "        \n",
    "        C = tf.concat([Cmat, Crow], 0)\n",
    "        return C\n",
    "    \n",
    "    \n",
    "    if (n % 2**steps) != 0:\n",
    "        print(\"Statics Peel 2\")\n",
    "        extra_cols = n % (2**steps)\n",
    "        \n",
    "        Cmat = bini(A[:, :n-extra_cols], B[:n-extra_cols,:], steps, e)\n",
    "        \n",
    "        A_slice = A[:, n-extra_cols:]\n",
    "        B_slice = B[n-extra_cols:, :]\n",
    "        (_, slice_len) = A_slice.get_shape().as_list()\n",
    "        \n",
    "        if slice_len == 1:\n",
    "            #vector case\n",
    "            Ccol = tf.matmul(tf.expand_dims(A_slice, 1), tf.expand_dims(B_slice, 0))\n",
    "        \n",
    "        else: \n",
    "            Ccol = tf.matmul(A_slice, 1, B_slice)\n",
    "        \n",
    "        C = tf.add(Cmat, Ccol)\n",
    "        return C\n",
    "    \n",
    "    \n",
    "    if (p % 2**steps) != 0:\n",
    "        print(\"Statics Peel 3\")\n",
    "        multiP = p//(2**steps) #multipler to find how large to make the bini matrix\n",
    "        extra_cols = p % (2**steps)\n",
    "        \n",
    "        Cmat = bini(A, B[:, :p-extra_cols], steps, e)\n",
    "        \n",
    "        B_slice = B[:, p-extra_cols:]\n",
    "        (_, slice_len) = B_slice.get_shape().as_list()\n",
    "        \n",
    "        if slice_len == 1:\n",
    "            #vector case\n",
    "            Ccol = tf.matmul(A, tf.expand_dims(B_slice, 1))\n",
    "        else:\n",
    "            Ccol = tf.matmul(A, B_slice)\n",
    "        \n",
    "        C = tf.concat([Cmat, Ccol], 1)\n",
    "        return C\n",
    "    \n",
    "    \"\"\"\n",
    "    Dynamic peeling causes issues because the ideal epsilon value is determined by \n",
    "    the shape of the matrix and in dynamic peeling, the shape of the matrix\n",
    "    is changed every recursive step which results in dimensions with a different \n",
    "    ideal epsilon value\n",
    "    \n",
    "    #Dynamic peeling\n",
    "    if m % 3 == 1:\n",
    "        C[:m-1, :] = bini(A[:m-1,:],B, steps, e)\n",
    "        C[m-1,:] = A[m-1,:]@B\n",
    "        return C\n",
    "    if m % 3 == 2:\n",
    "        C[:m-2, :] = bini(A[:m-2,:],B, steps, e)\n",
    "        C[m-2:,:] = A[m-2:,:]@B\n",
    "        return C\n",
    "    if n % 2 == 1:\n",
    "        C = bini(A[:, :n-1], B[:n-1,:], steps, e)\n",
    "        C = C + np.outer(A[:,n-1],B[n-1,:])\n",
    "        return C\n",
    "    if p % 2 == 1:\n",
    "        C[:, :p-1] = bini(A, B[:,:p-1], steps, e)\n",
    "        C[:,p-1] = A@B[:,p-1]\n",
    "        return C\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    # split up the matricies once rows of A are divisible by 3\n",
    "    # and cols of A and rows and cols of are divisible by 2\n",
    "    m2 = int(m/3) #first third of the rows of A\n",
    "    m3 = m2*2     #second third of the rows of A\n",
    "    n2 = int(n/2) #half of the cols of A\n",
    "    p2 = int(p/2) #half of the cols of B\n",
    "    #nn2 = int(nn/2) # half of the rows of B\n",
    "    \n",
    "    A1 = A[:m2, :n2]\n",
    "    A2 = A[m2:m3, :n2]\n",
    "    A3 = A[m3:, :n2]\n",
    "    A4 = A[:m2, n2:]\n",
    "    A5 = A[m2:m3, n2:]\n",
    "    A6 = A[m3:, n2:]\n",
    "    \n",
    "    B1 = B[:n2, :p2]\n",
    "    B2 = B[:n2, p2:]\n",
    "    B3 = B[n2:, :p2]\n",
    "    B4 = B[n2:, p2:]\n",
    "    \n",
    "    #bini(A, B, steps, e=0.1)\n",
    "    # conquer\n",
    "    \n",
    "    # check if TF has a special fun for scalar mul\n",
    "    M1  = bini(tf.add(A1, A5)                  , tf.add(tf.scalar_mul(e, B1), B4)     , steps-1, e) \n",
    "    M2  = bini(A5                              , tf.subtract(-B3, B4)                 , steps-1, e)\n",
    "    M3  = bini(A1                              , B4                                   , steps-1, e)\n",
    "    M4  = bini(tf.add(tf.scalar_mul(e,A4), A5) , tf.add(tf.scalar_mul(-e, B1), B3)    , steps-1, e)\n",
    "    M5  = bini(tf.add(A1, tf.scalar_mul(e, A4)), tf.add(tf.scalar_mul(e, B2), B4)     , steps-1, e)\n",
    "    M6  = bini(tf.add(A2, A6)                  , tf.add(B1, tf.scalar_mul(e, B4))     , steps-1, e)\n",
    "    M7  = bini(A2                              , tf.subtract(-B1, B2)                 , steps-1, e) \n",
    "    M8  = bini(A6                              , B1                                   , steps-1, e)\n",
    "    M9  = bini(tf.add(A2, tf.scalar_mul(e, A3)), tf.subtract(B2, tf.scalar_mul(e, B4)), steps-1, e)\n",
    "    M10 = bini(tf.add(tf.scalar_mul(e, A3), A6), tf.add(B1, tf.scalar_mul(e, B3))     , steps-1, e)\n",
    "    \n",
    "    # nation building\n",
    "    # gonna have to con cat these, cant use indexing to put this together\n",
    "    C1 = tf.scalar_mul((1/e), tf.add(M1, tf.subtract(tf.add(M2, M4), M3)))    #C[:m2, :p2]\n",
    "    C2 = tf.scalar_mul((1/e), tf.add(-M3, M5))                                #C[:m2, p2:]\n",
    "    C3 = tf.add(M4, tf.subtract(M6, M10))                                     #C[m2:m3, :p2] error from bini paper -M10 from +M10\n",
    "    C4 = tf.subtract(M1, tf.add(M5, M9))                                      #C[m2:m3, p2:] error from bini paper -M5 from +M5\n",
    "    C5 = tf.scalar_mul((1/e), tf.add(-M8,M10))                                #C[m3:, :p2]\n",
    "    C6 = tf.scalar_mul((1/e), ( tf.add(M6, tf.subtract(tf.add(M7, M9), M8)))) #C[m3:, p2:]\n",
    "    \n",
    "    \n",
    "    # need to put all of the above pieces together\n",
    "    C13 = tf.concat([C1, C3], 0)\n",
    "    C135 = tf.concat([C13, C5], 0)\n",
    "    C24 = tf.concat([C2, C4], 0)\n",
    "    C246 = tf.concat([C24, C6], 0)\n",
    "    C = tf.concat([C135, C246], 1)\n",
    "    \"\"\"\n",
    "    t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "    t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "    tf.concat([t1, t2], 0)  # [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "    tf.concat([t1, t2], 1)  # [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]\n",
    "    \n",
    "    This is the notation I use from Bini's 1980 paper\n",
    "\n",
    "    |A1, A4|  |B1, B2|  =  |C1, C2|\n",
    "    |A2, A5|  |B3, B4|     |C3, C4|\n",
    "    |A3, A6|               |C5, C6|\n",
    "    \"\"\"\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_e(steps):\n",
    "    e = (2**-52)**(1/(1+steps))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statics Peel 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 3 for 'MatMul_1822' (op: 'MatMul') with input shapes: [1,1,4], [4,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 3 for 'MatMul_1822' (op: 'MatMul') with input shapes: [1,1,4], [4,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-0daf375ce29a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalculate_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-7e6482d52602>\u001b[0m in \u001b[0;36mbini\u001b[1;34m(A, B, steps, e)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mslice_len\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;31m#vector case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mCrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[1;32m-> 1891\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   2435\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2436\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2437\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2956\u001b[0m         op_def=op_def)\n\u001b[0;32m   2957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2958\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2209\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2210\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 2 but is rank 3 for 'MatMul_1822' (op: 'MatMul') with input shapes: [1,1,4], [4,4]."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = np.random.rand(10,4)\n",
    "    w = np.identity(4)\n",
    "\n",
    "    a = tf.constant(a, dtype=tf.float64)\n",
    "    w = tf.constant(w)\n",
    "    \n",
    "    m = sess.run(tf.matmul(a,w))\n",
    "    b = sess.run(bini(a,w,steps, calculate_e(steps)))\n",
    "    \n",
    "    print(\"A: \\n\", sess.run(a), '\\n')\n",
    "    print(\"matmul: \\n\", m)\n",
    "    print(\"Bini: \\n\", b)\n",
    "    print(\"\\n m-s: \\n\", m-b, '\\n')\n",
    "    print(\"Bini Error: \", la.norm(b-m, 'fro')/la.norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "    a = np.random.rand(4,4)\n",
    "    w = np.identity(4)\n",
    "\n",
    "    a = tf.constant(a, dtype=tf.float64)\n",
    "    w = tf.constant(w)\n",
    "    \n",
    "    a = sess.run(a)\n",
    "    w = sess.run(w)\n",
    "    \n",
    "    s = strass(a,w, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
