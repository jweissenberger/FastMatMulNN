{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using Strassens Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackweissenberger/anaconda3/envs/fastMM/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seed = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strass(A, B, steps):\n",
    "  \n",
    "    #Check Dimensions\n",
    "    # tensor.get_shape().as_list()\n",
    "    (m, n) = A.get_shape().as_list()\n",
    "    (nn, p) = B.get_shape().as_list()\n",
    "\n",
    "    #old code case m, n, nn, and p as ints\n",
    "    \n",
    "    if n != nn: raise ValueError(\"incompatible dimensions\")\n",
    "    C = tf.zeros([m,p])\n",
    "    \n",
    "    #Base case\n",
    "    if steps == 0 or m ==1 or n ==1 or p == 1:\n",
    "        C = tf.matmul(A,B)\n",
    "        return C\n",
    "    \n",
    "    #Dynamic peeling\n",
    "    # *****************\n",
    "    if m % 2 == 1:\n",
    "        #C[:m-1, :] \n",
    "        Cmat= strass(A[:m-1,:],B, steps)\n",
    "        #C[m-1,:], need to expand the dims b/c tf.matmul doesn't work for 1D vectors \n",
    "        Crow = tf.matmul(tf.expand_dims(A[m-1,:],0),B)\n",
    "        return tf.concat([Cmat, Crow], 0)\n",
    "    if n % 2 == 1:\n",
    "        Cmat = strass(A[:, :n-1], B[:n-1,:], steps)\n",
    "        C = tf.add(Cmat,  tf.matmul(tf.expand_dims(A[:,n-1],1),tf.expand_dims(B[n-1,:],0)))\n",
    "        return C\n",
    "    if p % 2 == 1:\n",
    "        #C[:, :p-1]\n",
    "        Cmat = strass(A, B[:,:p-1], steps)\n",
    "        #C[:,p-1]\n",
    "        Ccol = tf.matmul(A,tf.expand_dims(B[:,p-1],1))\n",
    "        return tf.concat([Cmat, Ccol], 1)\n",
    "    \n",
    "    # divide when m, n and p are all even\n",
    "    m2 = int(m/2)\n",
    "    n2 = int(n/2)\n",
    "    p2 = int(p/2)\n",
    "    A11 = A[:m2,:n2] \n",
    "    A12 = A[:m2,n2:]\n",
    "    A21 = A[m2:,:n2] \n",
    "    A22 = A[m2:,n2:]\n",
    "    B11 = B[:n2,:p2]   \n",
    "    B12 = B[:n2,p2:]\n",
    "    B21 = B[n2:,:p2] \n",
    "    B22 = B[n2:,p2:]\n",
    "    \n",
    "    # conquer\n",
    "    M1 = strass(A11, tf.subtract(B12,B22)   ,steps-1)\n",
    "    M2 = strass(tf.add(A11,A12), B22   ,steps-1)\n",
    "    M3 = strass(tf.add(A21,A22),B11    ,steps-1)\n",
    "    M4 = strass(A22    ,tf.subtract(B21,B11),steps-1)\n",
    "    M5 = strass(tf.add(A11, A22), tf.add(B11, B22),steps-1)\n",
    "    M6 = strass( tf.subtract(A12,A22), tf.add(B21,B22),steps-1)\n",
    "    M7 = strass(tf.subtract(A11,A21), tf.add(B11, B12),steps-1)\n",
    "    \n",
    "    # conquer    \n",
    "    #C[:m2,:p2] \n",
    "    C11 = tf.add(tf.subtract(tf.add(M5, M4), M2), M6) \n",
    "    #C[:m2,p2:]\n",
    "    C12 = tf.add(M1, M2) \n",
    "    #C[m2:,:p2] \n",
    "    C21 = tf.add(M3,M4)\n",
    "    #C[m2:,p2:]\n",
    "    C22 = tf.subtract(tf.subtract(tf.add(M1,M5), M3), M7)\n",
    "    \n",
    "    # nation building\n",
    "    C1 = tf.concat([C11, C12], 1)\n",
    "    C2 = tf.concat([C21,C22], 1)\n",
    "    C = tf.concat([C1,C2], 0)\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 300\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here batch_size was none\n",
    "X = tf.placeholder(tf.float32, shape=(batch_size, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(batch_size), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I define the layers and their multiplication, typically, I would just use tf.matmul instead of strass, but here I have replaced it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        \n",
    "        Z = strass(X, W, 3) + b\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "#saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.91 Test accuracy 0.9032999420166016\n",
      "1 Train accuracy: 0.91 Test accuracy 0.9217330028057098\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        num_batches_in_test = mnist.test.num_examples // batch_size\n",
    "        for j in range(num_batches_in_test):\n",
    "            acc_test += accuracy.eval(feed_dict={X: mnist.test.images[j*batch_size:batch_size*(j+1)], \n",
    "                                                 y: mnist.test.labels[j*batch_size:batch_size*(j+1)]})\n",
    "        acc_test /= num_batches_in_test\n",
    "                                            \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy\", acc_test)\n",
    "\n",
    "    #save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "    #use the above line if you want to save and reuse the network later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 25: \n",
    "\n",
    "0 Steps: final test accuracy: 0.6235\n",
    "\n",
    "1 Step:  final test accuracy: 0.6249\n",
    "\n",
    "2 Steps: final test accuracy: 0.6377\n",
    "\n",
    "3 Steps: final test accuracy: 0.6348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 21:\n",
    "\n",
    "0 Steps: final test accuracy: 0.6629\n",
    "\n",
    "1 Step:  final test accuracy: 0.6617\n",
    "\n",
    "2 Steps: final test accuracy: 0.6306\n",
    "\n",
    "3 Steps: final test accuracy: 0.6439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 18:\n",
    "\n",
    "0 Steps: final test accuracy: 0.6612\n",
    "\n",
    "1 Step:  final test accuracy: 0.6332\n",
    "\n",
    "2 Steps: final test accuracy: 0.6238\n",
    "\n",
    "3 Steps: final test accuracy: 0.6286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check double vs single percision \n",
    "\n",
    "time the concats vs the actual matrix multiplication to say hey I'm limited by the tensorflow interface but if we worked around it, and created a better interface, we would have a speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
