{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using Strassens Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weisja15\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "seed = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strass(A, B, steps):\n",
    "  \n",
    "    #Check Dimensions\n",
    "    # tensor.get_shape().as_list()\n",
    "    (m,n) = A.get_shape().as_list()\n",
    "    (nn, p) = B.get_shape().as_list()\n",
    "\n",
    "    #old code case m, n, nn, and p as ints\n",
    "    \n",
    "    if n != nn: raise ValueError(\"incompatible dimensions\")\n",
    "    C = tf.zeros([m,p])\n",
    "    \n",
    "    #Base case\n",
    "    if steps == 0 or m ==1 or n ==1 or p == 1:\n",
    "        C = tf.matmul(A,B)\n",
    "        return C\n",
    "    \n",
    "    #Dynamic peeling\n",
    "    # *****************\n",
    "    if m % 2 == 1:\n",
    "        #C[:m-1, :] \n",
    "        Cmat= strass(A[:m-1,:],B, steps)\n",
    "        #C[m-1,:]\n",
    "        Crow = tf.matmul(tf.expand_dims(A[m-1,:],0),B)\n",
    "        return tf.concat([Cmat, Crow], 0)\n",
    "    if n % 2 == 1:\n",
    "        Cmat = strass(A[:, :n-1], B[:n-1,:], steps)\n",
    "        C = tf.add(Cmat,  tf.matmul(tf.expand_dims(A[:,n-1],1),tf.expand_dims(B[n-1,:],0)))\n",
    "        return C\n",
    "    if p % 2 == 1:\n",
    "        #C[:, :p-1]\n",
    "        Cmat = strass(A, B[:,:p-1], steps)\n",
    "        #C[:,p-1]\n",
    "        Ccol = tf.matmul(A,tf.expand_dims(B[:,p-1],1))\n",
    "        return tf.concat([Cmat, Ccol], 1)\n",
    "    \n",
    "    # divide when m, n and p are all even\n",
    "    m2 = int(m/2)\n",
    "    n2 = int(n/2)\n",
    "    p2 = int(p/2)\n",
    "    A11 = A[:m2,:n2] \n",
    "    A12 = A[:m2,n2:]\n",
    "    A21 = A[m2:,:n2] \n",
    "    A22 = A[m2:,n2:]\n",
    "    B11 = B[:n2,:p2]   \n",
    "    B12 = B[:n2,p2:]\n",
    "    B21 = B[n2:,:p2] \n",
    "    B22 = B[n2:,p2:]\n",
    "    \n",
    "    # conquer\n",
    "    M1 = strass(A11, tf.subtract(B12,B22)   ,steps-1)\n",
    "    M2 = strass(tf.add(A11,A12), B22   ,steps-1)\n",
    "    M3 = strass(tf.add(A21,A22),B11    ,steps-1)\n",
    "    M4 = strass(A22    ,tf.subtract(B21,B11),steps-1)\n",
    "    M5 = strass(tf.add(A11, A22), tf.add(B11, B22),steps-1)\n",
    "    M6 = strass( tf.subtract(A12,A22), tf.add(B21,B22),steps-1)\n",
    "    M7 = strass(tf.subtract(A11,A21), tf.add(B11, B12),steps-1)\n",
    "    \n",
    "    # conquer    \n",
    "    #C[:m2,:p2] \n",
    "    C11 = tf.add(tf.subtract(tf.add(M5, M4), M2), M6) \n",
    "    #C[:m2,p2:]\n",
    "    C12 = tf.add(M1, M2) \n",
    "    #C[m2:,:p2] \n",
    "    C21 = tf.add(M3,M4)\n",
    "    #C[m2:,p2:]\n",
    "    C22 = tf.subtract(tf.subtract(tf.add(M1,M5), M3), M7)\n",
    "    \n",
    "    C1 = tf.concat([C11, C12], 1)\n",
    "    C2 = tf.concat([C21,C22], 1)\n",
    "    C = tf.concat([C1,C2], 0)\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 300\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(batch_size, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(batch_size), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I define the layers and their multiplication, typically, I would just use tf.matmul instead of strass, but here I have replaced it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        \n",
    "        Z = strass(X, W, 3) + b\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.0846 Test accuracy: 0.0793\n",
      "1 Train accuracy: 0.1663 Test accuracy: 0.1624\n",
      "2 Train accuracy: 0.2582 Test accuracy: 0.2643\n",
      "3 Train accuracy: 0.3575 Test accuracy: 0.36\n",
      "4 Train accuracy: 0.4196 Test accuracy: 0.4345\n",
      "5 Train accuracy: 0.4757 Test accuracy: 0.4897\n",
      "6 Train accuracy: 0.5161 Test accuracy: 0.5359\n",
      "7 Train accuracy: 0.5684 Test accuracy: 0.5742\n",
      "8 Train accuracy: 0.596 Test accuracy: 0.6053\n",
      "9 Train accuracy: 0.6218 Test accuracy: 0.6286\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                            y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    #save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "    #use the above line if you want to save and reuse the network later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 25: \n",
    "\n",
    "0 Steps: final test accuracy: 0.6235\n",
    "\n",
    "1 Step:  final test accuracy: 0.6249\n",
    "\n",
    "2 Steps: final test accuracy: 0.6377\n",
    "\n",
    "3 Steps: final test accuracy: 0.6348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 21:\n",
    "\n",
    "0 Steps: final test accuracy: 0.6629\n",
    "\n",
    "1 Step:  final test accuracy: 0.6617\n",
    "\n",
    "2 Steps: final test accuracy: 0.6306\n",
    "\n",
    "3 Steps: final test accuracy: 0.6439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seed 18:\n",
    "\n",
    "0 Steps: final test accuracy: 0.6612\n",
    "\n",
    "1 Step:  final test accuracy: 0.6332\n",
    "\n",
    "2 Steps: final test accuracy: 0.6238\n",
    "\n",
    "3 Steps: final test accuracy: 0.6286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check double vs single percision \n",
    "\n",
    "time the concats vs the actual matrix multiplication to say hey I'm limited by the tensorflow interface but if we worked around it, and created a better interface, we would have a speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
